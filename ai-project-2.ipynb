{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"ai-project-2","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM9AJZyfAC//BJnXGG9EfAH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Na początku zamontowaliśmy dysk Google."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# import google drive\n","from google.colab import drive\n","\n","# mount google drive\n","drive.mount('/content/drive')\n"],"outputs":[],"metadata":{"id":"u3iDWEkQKpkA"}},{"cell_type":"markdown","source":["Następnie rozpakowaliśmy folder z danymi do `/content/data_dir`"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# unzip data.zip\n","!unzip \"/content/drive/MyDrive/studies/ai-project-2/data.zip\" -d /content/data_dir\n"],"outputs":[],"metadata":{"id":"ok_l4l0mLIO4"}},{"cell_type":"markdown","source":["Dalszym etapem było zaimportowanie potrzebnych bibliotek."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# import\n","import numpy as np\n","import os\n","import PIL\n","import PIL.Image\n","import tensorflow as tf\n","import tensorflow_datasets as tfds\n","import pathlib\n","import matplotlib.pyplot as plt\n","import random\n","import cv2\n","from sklearn.model_selection import train_test_split\n"],"outputs":[],"metadata":{"id":"DVgdxRpAd1KW"}},{"cell_type":"markdown","source":["Zapisaliśmy do zmiennej informację o ścieżce z danymi."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# data_dir\n","data_dir = \"/content/data_dir\"\n","data_dir = pathlib.Path(data_dir)\n"],"outputs":[],"metadata":{"id":"kdRsRLAFeVsb"}},{"cell_type":"markdown","source":["Obliczyliśmy ilość wsyztskich zdjęć."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# image_count\n","image_count = len(list(data_dir.glob('*/*.*')))\n"],"outputs":[],"metadata":{"id":"-1jO--EyebC0"}},{"cell_type":"markdown","source":["Ustawiliśmy `batch_size`, `img_height` i `img_width`."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# configs\n","batch_size = 3\n","img_height = 128\n","img_width = 128\n"],"outputs":[],"metadata":{"id":"6_ABSwZTensF"}},{"cell_type":"markdown","source":["Zapisaliśmy do tablicy listę kategorii."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# class names\n","class_names = np.array(sorted([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"]))\n"],"outputs":[],"metadata":{"id":"Rh1hhd8I16qx"}},{"cell_type":"markdown","source":["Zebraliśmy wszystkie ścieżki zdjęć z każdej kategorii."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# imagePaths\n","imagePaths = []\n","\n","for k, class_name in enumerate(class_names):\n","    for f in os.listdir(str(data_dir)+\"/\"+class_name):\n","        imagePaths.append([str(data_dir)+\"/\"+class_name+'/'+f, k])\n","\n","random.shuffle(imagePaths)\n"],"outputs":[],"metadata":{"id":"M05XDMSE17sw"}},{"cell_type":"markdown","source":["Zmieniliśmy rozmiary zdjęć, tak żeby każde miało taki sam oraz zapisaliśmy do jednej tablicy zdjęcia, a do drugiej odpowiadające im labele."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# data and labels\n","data = []\n","labels = []\n","\n","for imagePath in imagePaths:\n","    image = cv2.imread(imagePath[0])\n","    image = cv2.resize(image, (img_width, img_height))\n","    data.append(image)\n","    \n","    label = imagePath[1]\n","    labels.append(label)\n"],"outputs":[],"metadata":{"id":"rnE8ZGC819WY"}},{"cell_type":"markdown","source":["Jako że zdjęcia w AI/ML nie mogą być obsługiwane w skali [0, 255] na kolor, tylko w skali [0, 1], to zmieniamy je."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# scale the raw pixel intensities to the range [0, 1]\n","data = np.array(data, dtype=\"float\") / 255.0\n","labels = np.array(labels)\n"],"outputs":[],"metadata":{"id":"--RynZ2U1-tS"}},{"cell_type":"markdown","source":["Wyświtalmy wykres z kilkoma przykładowymi zdjęciami."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# debug\n","plt.subplots(3,4)\n","for i in range(12):\n","    plt.subplot(3,4, i+1)\n","    plt.imshow(data[i])\n","    plt.axis('off')\n","    plt.title(class_names[labels[i]])\n","plt.show()\n"],"outputs":[],"metadata":{"id":"N2L4OuLR1_qT"}},{"cell_type":"markdown","source":["Przygotowujemy dane treningowe i testowe oraz odpowiadujące im labele."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# partition the data into training and testing splits using 80% of\n","# the data for training and the remaining 20% for testing\n","(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.2, random_state=42)\n"],"outputs":[],"metadata":{"id":"ndIDyaru2BCr"}},{"cell_type":"markdown","source":["Tworzymy model `U-Net`."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# create model\n","model = tf.keras.Sequential([\n","  tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n","\n","  tf.keras.layers.Conv2D(64, (3,3), activation='elu', kernel_initializer='he_normal', padding='same'),\n","  tf.keras.layers.Dropout(0.1),\n","  tf.keras.layers.Conv2D(64, (3,3), activation='elu', kernel_initializer='he_normal', padding='same'),\n","  tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n","\n","  tf.keras.layers.Conv2D(128, (3,3), activation='elu', kernel_initializer='he_normal', padding='same'),\n","  tf.keras.layers.Dropout(0.1),\n","  tf.keras.layers.Conv2D(128, (3,3), activation='elu', kernel_initializer='he_normal', padding='same'),\n","  tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n","\n","  tf.keras.layers.Conv2D(256, (3,3), activation='elu', kernel_initializer='he_normal', padding='same'),\n","  tf.keras.layers.Dropout(0.1),\n","  tf.keras.layers.Conv2D(256, (3,3), activation='elu', kernel_initializer='he_normal', padding='same'),\n","  tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n","\n","  tf.keras.layers.Conv2D(512, (3,3), activation='elu', kernel_initializer='he_normal', padding='same'),\n","  tf.keras.layers.Dropout(0.1),\n","  tf.keras.layers.Conv2D(512, (3,3), activation='elu', kernel_initializer='he_normal', padding='same'),\n","  tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n","\n","  tf.keras.layers.Conv2D(1024, (3,3), activation='elu', kernel_initializer='he_normal', padding='same'),\n","  tf.keras.layers.Dropout(0.1),\n","  tf.keras.layers.Conv2D(1024, (3,3), activation='elu', kernel_initializer='he_normal', padding='same'),\n","\n","  tf.keras.layers.Conv2DTranspose(512, (2,2), strides=(2,2), padding='same'),\n","  tf.keras.layers.Conv2D(512, (3,3), activation='elu', kernel_initializer='he_normal', padding='same'),\n","  tf.keras.layers.Dropout(0.1),\n","  tf.keras.layers.Conv2D(512, (3,3), activation='elu', kernel_initializer='he_normal', padding='same'),\n","\n","  tf.keras.layers.Conv2DTranspose(256, (2,2), strides=(2,2), padding='same'),\n","  tf.keras.layers.Conv2D(256, (3,3), activation='elu', kernel_initializer='he_normal', padding='same'),\n","  tf.keras.layers.Dropout(0.1),\n","  tf.keras.layers.Conv2D(256, (3,3), activation='elu', kernel_initializer='he_normal', padding='same'),\n","\n","  tf.keras.layers.Conv2DTranspose(128, (2,2), strides=(2,2), padding='same'),\n","  tf.keras.layers.Conv2D(128, (3,3), activation='elu', kernel_initializer='he_normal', padding='same'),\n","  tf.keras.layers.Dropout(0.1),\n","  tf.keras.layers.Conv2D(128, (3,3), activation='elu', kernel_initializer='he_normal', padding='same'),\n","\n","  tf.keras.layers.Conv2DTranspose(64, (2,2), strides=(2,2), padding='same'),\n","  tf.keras.layers.Conv2D(64, (3,3), activation='elu', kernel_initializer='he_normal', padding='same'),\n","  tf.keras.layers.Dropout(0.1),\n","  tf.keras.layers.Conv2D(64, (3,3), activation='elu', kernel_initializer='he_normal', padding='same'),\n","\n","  tf.keras.layers.Conv2D(1, (1,1), activation='sigmoid'),\n","\n","  tf.keras.layers.Flatten(),\n","  tf.keras.layers.Dense(128, activation='relu'),\n","  tf.keras.layers.Dense(len(class_names))\n","])\n"],"outputs":[],"metadata":{"id":"yJJEFe2I2CeQ"}},{"cell_type":"markdown","source":["Kompilujemy model przy użyciu optymalizera `adam` i metryki `accuracy`."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# compile model\n","model.compile(\n","  optimizer='adam',\n","  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n","  metrics=['accuracy'])\n"],"outputs":[],"metadata":{"id":"ghBTLttb2FYI"}},{"cell_type":"markdown","source":["Trenujemy model na danych treningowych. Trening wykonujemy przez 3 epoki."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# train model\n","epochs = 3\n","model.fit(\n","  trainX,\n","  trainY,\n","  epochs=epochs\n",")\n"],"outputs":[],"metadata":{"id":"hNl_hWKy2GoH"}},{"cell_type":"markdown","source":["Na danych testowych predyktujemy model, dzięki czemu otrzymujemy otrzymujemy informacje, które obrazki pasowały do jakich kategorii i z jakim powodzeniem. Następnie obliczamy ile obrazków zostało przypisanych której kategorii, z czego wyświetlamy wykres dla wizualizacji."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["from numpy import argmax\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","\n","pred = model.predict(testX)\n","predictions = argmax(pred, axis=1) # return to label\n","\n","cm = confusion_matrix(testY, predictions)\n","\n","fig = plt.figure()\n","ax = fig.add_subplot(111)\n","cax = ax.matshow(cm)\n","plt.title('Model confusion matrix')\n","fig.colorbar(cax)\n","ax.set_xticklabels(['', *class_names])\n","ax.set_yticklabels(['', *class_names])\n","\n","for i in range(len(class_names)):\n","    for j in range(len(class_names)):\n","        ax.text(i, j, cm[j, i], va='center', ha='center')\n","\n","plt.xlabel('Predicted')\n","plt.ylabel('True')\n","plt.show()\n","\n","\n","accuracy = accuracy_score(testY, predictions)\n","print(\"Accuracy : %.2f%%\" % (accuracy*100.0))"],"outputs":[],"metadata":{"id":"-ng1tNAF2H9Z"}}]}