{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import PIL\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "# prepare data_dir\n",
    "data_dir = \"data_dir\"\n",
    "train_dir = pathlib.Path(data_dir + \"/train\")\n",
    "test_dir = pathlib.Path(data_dir + \"/test\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "# get train and test images\n",
    "train_images_paths = list(train_dir.glob(\"*/*.*\"))\n",
    "test_images_paths = list(test_dir.glob(\"*/*.*\"))\n",
    "\n",
    "train_images = np.array([])\n",
    "test_images = np.array([])\n",
    "\n",
    "i = 1;\n",
    "for fname in train_images_paths:\n",
    "    print(i, \"/\", len(train_images_paths))\n",
    "    train_images = np.append(train_images, PIL.Image.open(fname))\n",
    "    i += 1\n",
    "\n",
    "i = 1;\n",
    "for fname in test_images_paths:\n",
    "    print(i, \"/\", len(train_images_paths))\n",
    "    test_images = np.append(test_images, PIL.Image.open(fname))\n",
    "    i += 1\n",
    "\n",
    "print(train_images)\n",
    "print(test_images)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 / 244\n",
      "2 / 244\n",
      "3 / 244\n",
      "4 / 244\n",
      "5 / 244\n",
      "6 / 244\n",
      "7 / 244\n",
      "8 / 244\n",
      "9 / 244\n",
      "10 / 244\n",
      "11 / 244\n",
      "12 / 244\n",
      "13 / 244\n",
      "14 / 244\n",
      "15 / 244\n",
      "16 / 244\n",
      "17 / 244\n",
      "18 / 244\n",
      "19 / 244\n",
      "20 / 244\n",
      "21 / 244\n",
      "22 / 244\n",
      "23 / 244\n",
      "24 / 244\n",
      "25 / 244\n",
      "26 / 244\n",
      "27 / 244\n",
      "28 / 244\n",
      "29 / 244\n",
      "30 / 244\n",
      "31 / 244\n",
      "32 / 244\n",
      "33 / 244\n",
      "34 / 244\n",
      "35 / 244\n",
      "36 / 244\n",
      "37 / 244\n",
      "38 / 244\n",
      "39 / 244\n",
      "40 / 244\n",
      "41 / 244\n",
      "42 / 244\n",
      "43 / 244\n",
      "44 / 244\n",
      "45 / 244\n",
      "46 / 244\n",
      "47 / 244\n",
      "48 / 244\n",
      "49 / 244\n",
      "50 / 244\n",
      "51 / 244\n",
      "52 / 244\n",
      "53 / 244\n",
      "54 / 244\n",
      "55 / 244\n",
      "56 / 244\n",
      "57 / 244\n",
      "58 / 244\n",
      "59 / 244\n",
      "60 / 244\n",
      "61 / 244\n",
      "62 / 244\n",
      "63 / 244\n",
      "64 / 244\n",
      "65 / 244\n",
      "66 / 244\n",
      "67 / 244\n",
      "68 / 244\n",
      "69 / 244\n",
      "70 / 244\n",
      "71 / 244\n",
      "72 / 244\n",
      "73 / 244\n",
      "74 / 244\n",
      "75 / 244\n",
      "76 / 244\n",
      "77 / 244\n",
      "78 / 244\n",
      "79 / 244\n",
      "80 / 244\n",
      "81 / 244\n",
      "82 / 244\n",
      "83 / 244\n",
      "84 / 244\n",
      "85 / 244\n",
      "86 / 244\n",
      "87 / 244\n",
      "88 / 244\n",
      "89 / 244\n",
      "90 / 244\n",
      "91 / 244\n",
      "92 / 244\n",
      "93 / 244\n",
      "94 / 244\n",
      "95 / 244\n",
      "96 / 244\n",
      "97 / 244\n",
      "98 / 244\n",
      "99 / 244\n",
      "100 / 244\n",
      "101 / 244\n",
      "102 / 244\n",
      "103 / 244\n",
      "104 / 244\n",
      "105 / 244\n",
      "106 / 244\n",
      "107 / 244\n",
      "108 / 244\n",
      "109 / 244\n",
      "110 / 244\n",
      "111 / 244\n",
      "112 / 244\n",
      "113 / 244\n",
      "114 / 244\n",
      "115 / 244\n",
      "116 / 244\n",
      "117 / 244\n",
      "118 / 244\n",
      "119 / 244\n",
      "120 / 244\n",
      "121 / 244\n",
      "122 / 244\n",
      "123 / 244\n",
      "124 / 244\n",
      "125 / 244\n",
      "126 / 244\n",
      "127 / 244\n",
      "128 / 244\n",
      "129 / 244\n",
      "130 / 244\n",
      "131 / 244\n",
      "132 / 244\n",
      "133 / 244\n",
      "134 / 244\n",
      "135 / 244\n",
      "136 / 244\n",
      "137 / 244\n",
      "138 / 244\n",
      "139 / 244\n",
      "140 / 244\n",
      "141 / 244\n",
      "142 / 244\n",
      "143 / 244\n",
      "144 / 244\n",
      "145 / 244\n",
      "146 / 244\n",
      "147 / 244\n",
      "148 / 244\n",
      "149 / 244\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# train and test .npy path \n",
    "train_npy_path = train_dir + \"train.npy\"\n",
    "test_npy_path = test_dir + \"test.npy\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# save train and test images\n",
    "np.save(train_npy_path, train_images)\n",
    "np.save(test_npy_path, test_images)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load train and test images \n",
    "train_images = np.load(train_npy_path)\n",
    "test_images = np.load(test_npy_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# set parameters for the loader\n",
    "img_height = 1376\n",
    "img_width = 1038\n",
    "batch_size = 3\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# prepare training data set\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        train_dir,\n",
    "        validation_split=0.2,\n",
    "        subset=\"training\",\n",
    "        seed=123,\n",
    "        image_size=(img_height, img_width),\n",
    "        batch_size=batch_size)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# prepare validation data set\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        test_dir,\n",
    "        validation_split=0.2,\n",
    "        subset=\"validation\",\n",
    "        seed=123,\n",
    "        image_size=(img_height, img_width),\n",
    "        batch_size=batch_size)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# prepare class names\n",
    "class_names = train_ds.class_names\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Configure the dataset for performance\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# normalize data from [0, 255] to [0, 1]\n",
    "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# prepare normalized data set and use it\n",
    "train_normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "train_image_batch, train_labels_batch = next(iter(train_normalized_ds))\n",
    "\n",
    "val_normalized_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "val_image_batch, val_labels_batch = next(iter(val_normalized_ds))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# create model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.Rescaling(\n",
    "            1./255, input_shape=(img_height, img_width, batch_size)),\n",
    "    tf.keras.layers.Flatten(input_shape=(img_height, img_width)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(class_names))\n",
    "])\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# compile model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# model summary\n",
    "model.summary()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# train model\n",
    "epochs = 3\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs\n",
    ")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evaluate accuracy\n",
    "test_loss, test_acc = model.evaluate(val_image_batch.numpy(),  class_names, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "9df5a327c43981ca9ace5dd5272e3faa68cc4eff33fcc02905b53e0812b46f2b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}