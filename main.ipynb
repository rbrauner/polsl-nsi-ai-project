{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3iDWEkQKpkA"
      },
      "source": [
        "# import google drive\n",
        "from google.colab import drive\n",
        "\n",
        "# mount google drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ok_l4l0mLIO4"
      },
      "source": [
        "# unzip data.zip\n",
        "!unzip \"/content/drive/MyDrive/studies/ai-project/data.zip\" -d /content/data_dir\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP2tz6qHLwsc"
      },
      "source": [
        "# imports\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import pathlib\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kM7wwHDFXuVi"
      },
      "source": [
        "# set parameters for the loader\n",
        "img_height = 1376\n",
        "img_width = 1039\n",
        "batch_size = 3\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9Db_C88UOxG"
      },
      "source": [
        "# prepare data_dir\n",
        "data_dir = \"/content/data_dir\"\n",
        "data_dir = pathlib.Path(data_dir)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Kym0ufJVt-D"
      },
      "source": [
        "# count\n",
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utR8uvS7aiF-"
      },
      "source": [
        "# list_ds\n",
        "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'), shuffle=False)\n",
        "list_ds = list_ds.shuffle(image_count, reshuffle_each_iteration=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQ3VlHCUWUtJ"
      },
      "source": [
        "# class_names\n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZHt4tAeWgxh"
      },
      "source": [
        "# train_ds and val_ds\n",
        "val_size = int(image_count * 0.2)\n",
        "train_ds = list_ds.skip(val_size)\n",
        "val_ds = list_ds.take(val_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zZgv3WWW2Q3"
      },
      "source": [
        "# debug\n",
        "print(tf.data.experimental.cardinality(train_ds).numpy())\n",
        "print(tf.data.experimental.cardinality(val_ds).numpy())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iH77bu5CXFF8"
      },
      "source": [
        "# helper function process_path\n",
        "\n",
        "def get_label(file_path):\n",
        "  # convert the path to a list of path components\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\n",
        "  # The second to last is the class-directory\n",
        "  one_hot = parts[-2] == class_names\n",
        "  # Integer encode the label\n",
        "  return tf.argmax(one_hot)\n",
        "\n",
        "def decode_img(img):\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.io.decode_jpeg(img, channels=3)\n",
        "  # resize the image to the desired size\n",
        "  return tf.image.resize(img, [img_height, img_width])\n",
        "\n",
        "def process_path(file_path):\n",
        "  label = get_label(file_path)\n",
        "  # load the raw data from the file as a string\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = decode_img(img)\n",
        "  return img, label\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9fhCpQIXIQp"
      },
      "source": [
        "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "val_ds = val_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61vl9zAjX9hR"
      },
      "source": [
        "# debug\n",
        "for image, label in train_ds.take(1):\n",
        "  print(\"Image shape: \", image.numpy().shape)\n",
        "  print(\"Label: \", label.numpy())\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NW-IUrh4YGpu"
      },
      "source": [
        "# helper function configure_for_performance\n",
        "def configure_for_performance(ds):\n",
        "  ds = ds.cache()\n",
        "  ds = ds.shuffle(buffer_size=1000)\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "  return ds\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuLhM9xqYLtL"
      },
      "source": [
        "# configure for performance\n",
        "train_ds = configure_for_performance(train_ds)\n",
        "val_ds = configure_for_performance(val_ds)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fER9FJPZa8mE"
      },
      "source": [
        "# debug\n",
        "tfio.experimental.image.decode_tiff(train_ds[0])\n",
        "image_batch, label_batch = next(iter(train_ds))\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "  ax = plt.subplot(3, 3, i + 1)\n",
        "  plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
        "  label = label_batch[i]\n",
        "  plt.title(class_names[label])\n",
        "  plt.axis(\"off\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jI2J-KUYlHy"
      },
      "source": [
        "# create model\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(len(class_names))\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYKz49iKYvES"
      },
      "source": [
        "# compile model\n",
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4ggVu3YYzW1"
      },
      "source": [
        "# train model\n",
        "epochs=10\n",
        "model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98VcTFAbUOO-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "youGjQNML1xw"
      },
      "source": [
        "# prepare data_dir\n",
        "data_dir = \"data_dir\"\n",
        "train_dir = pathlib.Path(data_dir + \"/train\")\n",
        "test_dir = pathlib.Path(data_dir + \"/test\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDS5bcihL4Y3"
      },
      "source": [
        "# get train and test images\n",
        "train_images_paths = list(train_dir.glob(\"*/*.*\"))\n",
        "test_images_paths = list(test_dir.glob(\"*/*.*\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNuwsUkZMEgM"
      },
      "source": [
        "# set parameters for the loader\n",
        "img_height = 1376\n",
        "img_width = 1039\n",
        "batch_size = 3\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgOhjowRMGS7"
      },
      "source": [
        "# prepare training data set\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        train_dir,\n",
        "        validation_split=0.2,\n",
        "        subset=\"training\",\n",
        "        seed=123,\n",
        "        image_size=(img_height, img_width),\n",
        "        batch_size=batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-UNz-DbMJLa"
      },
      "source": [
        "# prepare test data set\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        test_dir,\n",
        "        validation_split=0.2,\n",
        "        subset=\"validation\",\n",
        "        seed=123,\n",
        "        image_size=(img_height, img_width),\n",
        "        batch_size=batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3Q00yqgMKt0"
      },
      "source": [
        "# prepare class names\n",
        "class_names = train_ds.class_names\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D84grUP-MMr7"
      },
      "source": [
        "# Configure the dataset for performance\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-oQlThpMOMs"
      },
      "source": [
        "# normalize data from [0, 255] to [0, 1]\n",
        "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eujs5xY4MPgv"
      },
      "source": [
        "# prepare normalized data set and use it\n",
        "train_normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "train_image_batch, train_labels_batch = next(iter(train_normalized_ds))\n",
        "\n",
        "test_normalized_ds = test_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "test_image_batch, test_labels_batch = next(iter(test_normalized_ds))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rs1WDT0OMQ6T"
      },
      "source": [
        "# create model\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(len(class_names))\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1FURyRRMSVR"
      },
      "source": [
        "# compile model\n",
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdQoGWefMUqu"
      },
      "source": [
        "# model summary\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkS2qOQjMXn2"
      },
      "source": [
        "# train model\n",
        "model.fit(\n",
        "  train_ds,\n",
        "  validation_data=test_ds,\n",
        "  epochs=3\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wdju0r1IMZNj"
      },
      "source": [
        "# Evaluate accuracy\n",
        "test_loss, test_acc = model.evaluate(test_ds, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}